<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Suchir Salhan</title>

  <meta name="author" content="Suchir Salhan">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="sas245.jpg">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-4VJBBSSEN8"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-4VJBBSSEN8');
  </script>
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Suchir Salhan
                  </p>
                   <p>I am a PhD Candidate in Computer Science at the <a href="https://www.cst.cam.ac.uk/research/themes/natural-language-processing">University of Cambridge</a>, researching Machine Learning and Natural Language Processing. I have a “Starred First” in my Bachelor of Arts and Distinction in my MEng in Computer Science and Linguistics from the University of Cambridge. My research focuses on Small-Scale Language Models to improve the interpretability of Foundation Models.  
                  </p>
                  <p>
                    My research primarily is concerned with engineering more cognitively plausible Foundation Models. This is an emerging research paradigm that attempts to improve the cognitive capabilities of state-of-the-art computational systems within a cognitively plausible environment. I have interests in Machine Learning Systems, the Theory of Deep Learning and Theoretical Linguistics. My ambition is to develop data-efficient Machine Learning systems that draw on human cognition. 
                  </p>
                  <p>

                    To this end, I'm particularly interested in developing novel machine learning techniques to build scalable neural architectures that draw on formal methods (e.g., category and type theory) utilised in theoretical formalisms in Cognitive Science. 
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:sas245@cam.ac.uk">Email</a> &nbsp;/&nbsp;
                    <a href="data/cv.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://twitter.com/suchirsalhan/">Twitter</a> &nbsp;/&nbsp;
                    <a href="www.linkedin.com/in/ssalhan">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/suchirsalhan/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/sas245.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/sas245.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                   My research currently focuses on building small-scale Transformer-based language models. I have engineered curriculum learning (CL) strategies inspired by cutting-edge Language Acquisition frameworks. 
                  </p>
                  <p>
                    I primarily work on Transformer-based Large Language Models (LLMs), and have previously drawn on Chomskyan models of Language Acquisition. I have previously worked with Multimodal Vision-Language Models in the Language Technology Lab with Prof Nigel Collier and Fangyu Liu (now Google DeepMind).Previously, I've probed vision-language models, exploring the semantic representations of CLIP. I have worked on Nearest Neighbour Algorithms for Offline Imitation Learning (IL). I have also worked on Explainable AI and Argumentation Mining,  Shortcut Learning in Natural Language Inference                    
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td colspan="2">
                  <h3 style="padding-left: 20px;">Published work</h3>
                </td>
              </tr>
              

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/succ.png" alt="successor" width="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://aclanthology.org/2023.conll-babylm.10/">
                    <span class="papertitle">Less is More: Pre-Training Cross-Lingual Small-Scale Language Models with Cognitively-Plausible Curriculum Learning Strategies.</span>
                  </a>
                  <br>
                  <strong>Suchir Salhan</strong>, 
                  <a href="https://www.richarddiehlmartinez.com/">Richard Diehl-Martinez</a>,
                  <a href="https://www.cst.cam.ac.uk/people/zg258">Zebulon Goriely</a>,
                  <a href="https://www.cl.cam.ac.uk/~pjb48/">Paula Buttery</a>
                  <br>
                  <em>In Preparation for CoNLL BabyLM Challenge (Paper Track)</em>, 2024;
                  <em>NeurIPS ATTRIB (Oral)</em>, 2023
                  <br>
                </td>
              </tr>

                <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/succ.png" alt="successor" width="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://aclanthology.org/2023.conll-babylm.10/">
                    <span class="papertitle">LLMs “off-the-shelf” or Pretrain-from-Scratch? Recalibrating Biases and Improving Transparency using Small-Scale Language Models.</span>
                  </a>
                  <br>
                  <strong>Suchir Salhan</strong>, 
                  <a href="https://www.richarddiehlmartinez.com/">Richard Diehl-Martinez</a>,
                  <a href="https://www.cst.cam.ac.uk/people/zg258">Zebulon Goriely</a>,
                  <a href="https://www.cl.cam.ac.uk/~apc38/">Andrew Caines</a>,
                  <a href="https://www.cl.cam.ac.uk/~pjb48/">Paula Buttery</a>
                  <br>
                  <em> Learning & Human Intelligence Group, Department of Computer Science & Technology </em>, 2024;
                  <br>
                </td>
              </tr>


              <tr>
                <td colspan="2">
                  <h3 style="padding-left: 20px;">Computational Projects</h3>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/personality.jpg" alt="attention heads" width="160">
                </td>
                <td width="75%" valign="middle">
                  <!-- <a href="https://example.com"> -->
                  <a href="https://www.cam.ac.uk/research/news/claims-ai-can-boost-workplace-diversity-are-spurious-and-dangerous-researchers-argue">
                    <span class="papertitle"> Argumentation Mining </span>
                  </a>
                  <br>
                  <strong>Suchir Salhan</strong>, 
                  <br>
                  <em> Department of Computer Science and Technology Natural Language Processing UROP </em>, 2020
                  <br>
                  <!--<a href="https://www.cam.ac.uk/research/news/claims-ai-can-boost-workplace-diversity-are-spurious-and-dangerous-researchers-argue">project </a>
                  /
                  <a href="https://example.com">arXiv</a>
                  /
                  <a href="https://example.com">reviews</a>
                  /
                  <a href="https://example.com">bibTeX</a>-->
                  <p> I was offered a UROP research project by my Director of Studies Prof Paula Buttery and Dr Andrew Caines. I worked under the supervision of computational linguists from the Automated Language Teaching and Assessment (ALTA) group in the Department of Computer Science and Technology. I was the only first-year student admitted to the two-month UROP programme. I worked on a project in collaboration with Thiemo Wambsganss on developing the back-end machine learning architecture for an application that supports the argumentation skills of English language learners. I trained and evaluated the performance of state-of-the-art transformer language models on downstream argumentation mining tasks, began working on the deployment of the pre-trained model in the application, and submitted the ethics application for the experimental evaluation of the educational outcomes of the application. I presented my work to members of the ALTA group and the project sponsors from Cambridge Assessment who funded my UROP project. I also had the opportunity to attend machine learning classes, and seminars on Dialogue Systems, Ethics in NLP, active learning paradigms and educational technology. 
                  </p>
                </td>
              </tr>
              
  
  

              
            </tbody>
          </table>
          <!-- 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Community</h2>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Miscellanea</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                  <br>
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member,
                    CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cs188.jpg" alt="cs188">
                </td>
                <td width="75%" valign="center">
                  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
                    CS188 Spring 2011</a>
                  <br>
                  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
                    CS188 Fall 2010</a>
                  <br>
                  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                    Edition</a>
                </td>
              </tr>


              <tr>
                <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                  <h2>Basically <br> Blog Posts</h2>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                  <br>
                  <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
                    Functions</a>
                  <br>
                  <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                  <br>
                  <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How
                    Can Academics Adapt?</a>
                </td>
              </tr>


            </tbody>
          </table> -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    © Suchir Salhan 2024 
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
