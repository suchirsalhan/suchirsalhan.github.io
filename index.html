<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Euan Ong</title>

  <meta name="author" content="Euan Ong">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="favicon.ico">
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-4VJBBSSEN8"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-4VJBBSSEN8');
  </script>
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Euan Ong
                  </p>
                  <p>I've just finished my undergraduate degree in Computer Science at the University of Cambridge (where I ranked 1st / ~120 every year). I'm currently working on adversarial robustness at <a href="https://www.anthropic.com/">Anthropic</a> for a year, before starting a Ph.D. in 'abstractions-first' mechanistic interpretability at <a href="https://csail.mit.edu/">MIT</a> with <a href="https://www.mit.edu/~jda/">Jacob Andreas</a> and <a href="https://people.csail.mit.edu/asolar/">Armando Solar-Lezama</a>.
                  </p>
                  <p>
                    My ambition is to develop powerful, yet safe and <a
                      href="https://transformer-circuits.pub/">interpretable</a>
                    abstract reasoners, whose
                    internal
                    state and behaviour remain <a href="https://arxiv.org/abs/2305.02469">transparent to the end
                      user</a>.
                  </p>
                  <p>
                    To this end, I'm particularly interested in exploring how the mathematical toolkits we use to
                    understand and structure programs ‒ such as <a
                      href="https://ai.stanford.edu/blog/causal-abstraction/">formal methods</a>,
                    <a href="https://colah.github.io/posts/2015-09-NN-Types-FP/">types</a> and <a
                      href="https://cats.for.ai/">category theory</a> ‒ can
                    inspire new ways
                    to both reverse-engineer existing neural networks, and build scalable neurosymbolic systems.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:euan+site@ong.ac">Email</a> &nbsp;/&nbsp;
                    <a href="data/cv.pdf">CV</a> &nbsp;/&nbsp;
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                    <a href="https://scholar.google.com/citations?user=vT2qcI0AAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://twitter.com/euan_ong/">Twitter</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/euanong/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/euanong/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/euanong.jpeg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/euanong_circle.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    So far, my research has broadly focused on studying the behaviour of neural networks <i>in
                      vitro</i>:
                    understanding both how they generalise when learning to perform abstract tasks, and
                    what
                    this tells us about the algorithms they've learned in order to do so.
                  </p>
                  <p>
                    Previously, I've probed the foundations of <a href="https://arxiv.org/abs/2105.02761">neural
                      algorithmic
                      reasoning</a>, explored attacks on vision-language models, and poked language model
                    representations
                    with a stick.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td colspan="2">
                  <h3 style="padding-left: 20px;">Published work</h3>
                </td>
              </tr>
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/nap.png" alt="nap" width="150" style="margin: 5px">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-990.pdf">
                    <span class="papertitle">Probing the Foundations of Neural Algorithmic Reasoning</span>
                  </a>
                  <br>
                  <strong>Euan Ong</strong>
                  <br>
                  <em>Technical Report</em>, 2023; <em>ICML Differentiable Almost Everything (Spotlight)</em>, 2024
                  <br>
                  <a href="https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-990.html">abstract</a>
                  /
                  <a href="https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-990.pdf">full text</a>
                  /
                  <a href="https://probing-nar.notion.site/">project page</a>
                  <p>
                    
                    I explored a fundamental claim of <a href="https://arxiv.org/abs/2105.02761">neural algorithmic reasoning</a>, and found evidence to refute it through statistically robust ablations. Based on my observations, I developed a way to parallelise differentiable algorithms that preserves their efficiency and correctness guarantees while alleviating their performance bottlenecks. This work formed part of my Bachelor's thesis, which won the CS department's <em><a href="data/best_dissertation_award.pdf">Best Dissertation Award</a></em>.</p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/succ.png" alt="successor" width="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2312.09230.pdf">
                    <span class="papertitle">Successor Heads: Recurring, Interpretable Attention Heads In The Wild</span>
                  </a>
                  <br>
                  <a href="https://r-gould.github.io/">Rhys Gould</a>, 
                  <strong>Euan Ong</strong>, 
                  <a href="https://go281.user.srcf.net/">George Ogden</a>,
                  <a href="https://arthurconmy.github.io/about/">Arthur Conmy</a>
                  <br>
                  <em>ICLR</em>, 2024;
                  <em>NeurIPS ATTRIB (Oral)</em>, 2023
                  <br>
                  <a href="https://arxiv.org/abs/2312.09230">arXiv</a>
                  /
                  <a href="https://openreview.net/forum?id=kvcbV8KQsi">reviews</a>
                  /
                  <a href="https://successor-heads.notion.site/">project page</a>
                  /
                  <a href="https://x.com/rgould0/status/1737261015245451399">tweeprint</a>
                  <p>We discovered <em>successor heads</em>: attention heads present in a range of LLMs that increment tokens from ordinal sequences (e.g. numbers, months and days). We isolated a common numeric subspace within embedding space, that for any given token (e.g. 'February'), encodes the index of that token within its ordinal sequence (e.g. months). We also found that numeric token representations can be decomposed into interpretable features representing the value of the token <em>mod 10</em>, which can be used to edit the numeric value of the representation via vector arithmetic.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/hijacks.png" alt="hijacks" width="160" height="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/pdf/2309.00236.pdf">
                    <span class="papertitle">Image Hijacks: Adversarial Images can Control Generative Models at
                      Runtime</span>
                  </a>
                  <br>
                  <a href="https://petar-v.com/">Luke Bailey</a>*, <strong>Euan Ong*</strong>, <a
                    href="http://people.eecs.berkeley.edu/~russell/">Stuart Russell</a>, <a
                    href="http://scottemmons.com/">Scott Emmons</a> (* denotes equal contribution)
                  <br>
                  <em>ICML</em>, 2024
                  <br>
                  <a href="https://arxiv.org/abs/2309.00236">arXiv</a>
                  /
                  <a href="https://image-hijacks.github.io/">project page + demo</a>
                  /
                  <a href="https://twitter.com/emmons_scott/status/1704166628089565262">tweeprint</a>
                  <p>We discovered that adversarial images can hijack the behaviour of vision-language models (VLMs) at
                    runtime. We developed a general method for crafting these <i>image hijacks</i>,
                    and trained image hijacks forcing VLMs to output arbitrary text, leak their context window and
                    comply with harmful instructions. We also derived an algorithm to train hijacks forcing 
                    VLMs to behave as though they were given an arbitrary prompt, which we used to make them believe the Eiffel Tower is in Rome.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/lcm.png" alt="monoids" width="160" height="160">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://proceedings.mlr.press/v198/ong22a/ong22a.pdf">
                    <span class="papertitle">Learnable Commutative Monoids for Graph Neural Networks</span>
                  </a>
                  <br>
                  <strong>Euan Ong</strong>, <a href="https://petar-v.com/">Petar Veličković</a>
                  <br>
                  <em>Learning on Graphs Conference</em>, 2022
                  <br>
                  <a href="https://arxiv.org/abs/2212.08541">arXiv</a>
                  /
                  <a href="https://openreview.net/forum?id=WtFobB28VDey">reviews</a>
                  /
                  <a href="https://monoids.notion.site/">project page</a>
                  /
                  <a href="https://twitter.com/PetarV_93/status/1602298299083628544">tweeprint</a>
                  <p>Using ideas from abstract algebra and functional programming, we built a new GNN aggregator that
                    beats the state of the art on complex aggregation problems (especially out-of-distribution), while
                    remaining efficient and parallelisable on large graphs.</p>
                </td>
              </tr>

              <tr>
                <td colspan="2">
                  <h3 style="padding-left: 20px;">Other projects</h3>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/personality.jpg" alt="attention heads" width="160">
                </td>
                <td width="75%" valign="middle">
                  <!-- <a href="https://example.com"> -->
                  <a href="https://www.cam.ac.uk/research/news/claims-ai-can-boost-workplace-diversity-are-spurious-and-dangerous-researchers-argue">
                    <span class="papertitle">Personality Machine</span>
                  </a>
                  <br>
                  <strong>Euan Ong</strong>*, 
                  <a href="https://www.linkedin.com/in/jamie-chen-a186161b4/">Jamie Chen</a>*,
                  <a href="https://www.linkedin.com/in/kyra-zhou/">Kyra Zhou</a>*,
                  <a href="https://www.linkedin.com/in/marcus-handley-a2a6b1179/">Marcus Handley</a>*,
                  <a href="https://www.linkedin.com/in/mingle-chen-8b4986181/">Mingle Chen</a>*,
                  <a href="https://www.linkedin.com/in/ori-vasilescu-b973a722a/">Ori Vasilescu</a>*,
                  <a href="https://www.eleanordrage.com/">Eleanor Drage</a>
                  (* denotes equal contribution)
                  <br>
                  <em>CST Group Project</em>, 2022
                  <br>
                  <!--<a href="https://www.cam.ac.uk/research/news/claims-ai-can-boost-workplace-diversity-are-spurious-and-dangerous-researchers-argue">project </a>
                  /
                  <a href="https://example.com">arXiv</a>
                  /
                  <a href="https://example.com">reviews</a>
                  /
                  <a href="https://example.com">bibTeX</a>-->
                  <p>In collaboration with the Centre for Gender Studies at Cambridge, we built a tool highlighting the questionable logic behind the use of AI-driven personality assessments often used in hiring. Our tool demonstrates how arbitrary changes in facial expression, clothing, lighting and background can give radically different personality readings, and was featured in <a href="https://www.bbc.co.uk/news/technology-63228466">the BBC</a> and <a href="https://www.telegraph.co.uk/news/2022/10/10/why-shouldnt-wear-glasses-interview-robot/">the Telegraph</a>.
                  </p>
                </td>
              </tr>
              
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/ddl.png" alt="attention heads" width="160" height="160">
                </td>
                <td width="75%" valign="middle">
                  <!-- <a href="https://example.com"> -->
                  <a>
                    <span class="papertitle">Dissecting Deep Learning for Systematic Generalisation</span>
                  </a>
                  <br>
                  <strong>Euan Ong</strong>, <a href="https://www.linkedin.com/in/etaash-katiyar-77108818b/">Etaash
                    Katiyar</a>, <a href="https://www.linkedin.com/in/kai-en-chong-a10a9a18b">Kai-En Chong</a>, <a
                    href="https://albertqjiang.github.io/">Albert
                    Qiaochu Jiang</a>
                  <br>
                  <em>Informal research</em>, 2021
                  <br>
                  <!-- <a href="https://example.com">project page</a>
                  /
                  <a href="https://example.com">arXiv</a>
                  /
                  <a href="https://example.com">reviews</a>
                  /
                  <a href="https://example.com">bibTeX</a> -->
                  <p>We investigated the capabilities of transformers to systematically generalise when learning to
                    recognise formal languages (such as
                    <span style="font-variant: small-caps;">Parity</span> and <span
                      style="font-variant: small-caps;">2-Dyck</span>), empirically corroborating various <a
                      href="https://arxiv.org/abs/1906.06755">theoretical claims</a> about transformer generalisation.
                    Inspired by our observations, we
                    derived a parallel, stackless algorithm for recognising <span
                      style="font-variant: small-caps;">2-Dyck</span> that could (in principle) be
                    implemented by a transformer with a constant number of attention layers.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle;text-align:center">
                  <img src="images/oxtd.png" alt="oxtd" width="140" height="140">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://drive.google.com/file/d/1UKkUcnq0CX-aq3c3o_-9xJdy7rKsytZ6/view?usp=sharing">
                    <span class="papertitle">Object Detection in Thermal Imagery via Convolutional Neural
                      Networks</span>
                  </a>
                  <br>
                  <strong>Euan Ong</strong>, 
                  <a href="https://www.cs.ox.ac.uk/people/niki.trigoni/">Niki Trigoni</a>, 
                  <a href="https://portobgusmao.com/">Pedro Porto Barque de Gusmão</a>
                  <br>
                  <em>Technical report</em>, 2019
                  <br>
                  <!-- <a href="https://example.com">project page</a>
                  /
                  <a href="https://example.com">arXiv</a>
                  /
                  <a href="https://example.com">reviews</a>
                  /
                  <a href="https://example.com">bibTeX</a> -->
                  <p>
                    We trained a Faster R-CNN object detection network to identify landmarks (e.g. doors and windows) in
                    thermal images of indoor environments, with applications in the development of navigational aids for
                    search and rescue operations.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- 
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Community</h2>
                </td>
              </tr>
            </tbody>
          </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td>
                  <h2>Miscellanea</h2>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="20">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
                <td width="75%" valign="center">
                  <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                  <br>
                  <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                  <br>
                  <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member,
                    CVPR 2021</a>
                  <br>
                  <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                  <br>
                  <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/cs188.jpg" alt="cs188">
                </td>
                <td width="75%" valign="center">
                  <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor,
                    CS188 Spring 2011</a>
                  <br>
                  <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor,
                    CS188 Fall 2010</a>
                  <br>
                  <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd
                    Edition</a>
                </td>
              </tr>


              <tr>
                <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                  <h2>Basically <br> Blog Posts</h2>
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                  <br>
                  <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain
                    Functions</a>
                  <br>
                  <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                  <br>
                  <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How
                    Can Academics Adapt?</a>
                </td>
              </tr>


            </tbody>
          </table> -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Design inspired by <a href="https://github.com/jonbarron/jonbarron_website"
                      style="font-size:small">Jon Barron</a>'s site.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>