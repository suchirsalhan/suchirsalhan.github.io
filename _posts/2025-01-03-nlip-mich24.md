---
layout: post
title:  "NLIP Seminars Michaelmas 2024"
publish_author: Suchir Salhan
publish_venue: Department of Computer Science & Technology
publish_year: 2024
categories: []
image: assets/images/plc.png
featured: False
thesis: False
software: False
blog: True
---

The Cambridge Natural Language & Information Processing (NLIP) Seminars are series of weekly talks from researchers in the fields of Natural Language Processing and Computational Linguistics, and adjacent fields including Machine Learning and Linguistics/Cognitive Science. I had the privilege of organising the seminars in the first term of my PhD, inheriting the seminar from Richard Diehl Martinez and Eric Chamoun. It was an interesting exercise, alongside getting my teeth into my own research. The aim of the seminar series, as is the case for any term card, is to provide researchers in our group the opportunity to engage with thought-provoking and potentially challenging ‘high-level’ research ideas. This short post summarises some (personal) key takeaways of the research talks from the speakers that I invited to speak in our Michaelmas Term speakers and finish off with some of my own personal thoughts. 


<h2 class="font-weight-bold mb-4 serif-font"> Cognition, Linguistics and NLP </h2>

<h3 class="font-weight-bold mb-4 serif-font">What about Linguistics? (Prof Janet Pierrehumbert, University of Oxford)</h3>


 <h3 class="font-weight-bold mb-4 serif-font"> Truth-Conditional Semantics at Scale 
 (Dr Guy Emerson, University of Cambridge)</h3>


 <h3 class="font-weight-bold mb-4 serif-font"> Phonemic Pre-Training  (Zebulon Goriely, University of Cambridge)</h3>

  <h3 class="font-weight-bold mb-4 serif-font"> Lyric Generation  (Yiwen Chen, University of Cambridge)</h3>


<h2 class="font-weight-bold mb-4 serif-font"> Language Models  </h2>

<h3 class="font-weight-bold mb-4 serif-font"> Human Feedback (Max Bartolo, Cohere)</h3>

Max Bartolo from Cohere – making him our only speaker from industry this term– delivered a talk entitled “10 slides on Human Feedback”. Focussed reward models which are trained to predict a score reflecting on human preference (e.g., Reinforcement Learning from Human Feedback), Max provided a survey of different perspectives on aligning outputs of a language model to user preferences. The overall takeaway was that any notion of ‘feedback’ is inherently subjective. While this is not surprising, it means that we need to move to a position of having finer granularity to provide better rewards and additionally have more flexible models that can overcome biases. 

Max highlighted the PRISM Alignment Project from NEURIPS 2024, a dataset with sociodemographic and preference (Kirk et al 2024 https://arxiv.org/pdf/2404.16019). 

However, like most efforts in NLP, the annotation efforts are computationally expensive. It is, therefore, not surprising that there are research efforts twoars 

<h3 class="font-weight-bold mb-4 serif-font"> Tokenisers & Adaptive Memory (Dr Edoardo Ponti (Edinburgh/NVIDIA) and Benjamin Minixhofer (Language Technology Lab, Cambridge University)</h3>




